import json
import os
import re
from pathlib import Path
from typing import Any, List

import requests
from loguru import logger
from requests.adapters import HTTPAdapter, Retry

# --- å…¨åŸŸåƒæ•¸è¨­å®š ---
DATA_FOLDER = os.getenv("DATA_FOLDER", "temp")
OUTPUT_PATH = Path(DATA_FOLDER + "/dining.json")

HEADERS = {
    "accept": "*/*",
    "accept-encoding": "gzip, deflate, br",
    "accept-language": "zh-TW,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6,zh-CN;q=0.5",
    "dnt": "1",
    "host": "ddfm.site.nthu.edu.tw",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
}

# å»ºç«‹ requests session ä¸¦è¨­å®š retry æ©Ÿåˆ¶
session = requests.Session()
retries = Retry(
    total=5,  # ç¸½å…±é‡è©¦ 5 æ¬¡
    backoff_factor=1,  # æŒ‡æ•¸é€€é¿ï¼š1 ç§’ã€2 ç§’ã€4 ç§’...
    status_forcelist=[500, 502, 503, 504, 408],
)
session.mount("https://", HTTPAdapter(max_retries=retries))

# é å…ˆç·¨è­¯æ­£è¦è¡¨é”å¼ï¼ˆæ”¹å–„æ•ˆèƒ½èˆ‡å¯è®€æ€§ï¼‰
DINING_REGEX = re.compile(r"const restaurantsData = (\[.*?)(?:\s+renderTabs)", re.S)


def parse_html(res_text: str) -> List[Any]:
    """
    è§£æç¶²é åŸå§‹ç¢¼ï¼Œæå–é¤å»³è³‡æ–™ï¼ˆJSON æ ¼å¼ï¼‰ã€‚
    è‹¥ç„¡æ³•æ‰¾åˆ°è³‡æ–™å‰‡å›å‚³ç©ºåˆ—è¡¨ã€‚

    åƒæ•¸:
        res_text (str): åŸå§‹ HTML å…§å®¹

    å›å‚³:
        List[Any]: è§£æå‡ºçš„é¤å»³è³‡æ–™åˆ—è¡¨
    """
    match = DINING_REGEX.search(res_text)
    if match is None:
        logger.error("â æ‰¾ä¸åˆ°é¤å»³è³‡æ–™çš„å…§å®¹")
        return []

    dining_data = match.group(1)
    # å°‡å–®å¼•è™Ÿæ›æˆé›™å¼•è™Ÿï¼Œä¸¦ç§»é™¤æ›è¡Œç¬¦è™Ÿ
    dining_data = dining_data.replace("'", '"').replace("\n", "")
    # ç§»é™¤å¤šé¤˜çš„é€—è™Ÿï¼Œä¾‹å¦‚ "..., ]" è®Šæˆ "...]"
    dining_data = re.sub(r",[ ]+?\]", "]", dining_data)
    try:
        data = json.loads(dining_data)
        return data
    except json.JSONDecodeError as e:
        logger.error(f"â JSON è§£ç¢¼éŒ¯èª¤: {e}")
        return []


def scrape_dining(path: Path) -> None:
    """
    çˆ¬å–é¤å»³åŠæœå‹™æ€§å» å•†çš„è³‡æ–™ï¼Œä¸¦å„²å­˜åˆ°æŒ‡å®šçš„ JSON æª”æ¡ˆä¸­ã€‚

    åƒæ•¸:
        path (Path): å„²å­˜çµæœçš„æª”æ¡ˆè·¯å¾‘
    """
    url = "https://ddfm.site.nthu.edu.tw/p/404-1494-256455.php?Lang=zh-tw"
    try:
        logger.info(f"ğŸ”— æ­£åœ¨å¾ {url} ç²å–è³‡æ–™")
        response = session.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()  # è‹¥ HTTP ç‹€æ…‹ç¢¼ä¸ç‚º 200ï¼Œå‰‡æ‹‹å‡ºç•°å¸¸
        response.encoding = "utf-8"
        logger.success("âœ… æˆåŠŸå–å¾—é¤å»³åŠæœå‹™æ€§å» å•†çš„è³‡æ–™")
    except requests.RequestException as e:
        logger.error(f"â çˆ¬å–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return

    dining_data = parse_html(response.text)
    if not dining_data:
        logger.error("â æœªèƒ½è§£æåˆ°ä»»ä½•é¤å»³è³‡æ–™ï¼Œå°‡ä¸é€²è¡Œå„²å­˜")
        return
    logger.debug(dining_data)

    try:
        with path.open("w", encoding="utf-8") as f:
            json.dump(dining_data, f, ensure_ascii=False, indent=4)
        logger.success(f'âœ… æˆåŠŸå°‡é¤å»³è³‡æ–™å„²å­˜åˆ° "{path}"')
    except IOError as e:
        logger.error(f"â å¯«å…¥æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


if __name__ == "__main__":
    scrape_dining(OUTPUT_PATH)
